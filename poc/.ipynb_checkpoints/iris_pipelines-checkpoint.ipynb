{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import preprocessing\n",
      "from sklearn import linear_model\n",
      "from sklearn import datasets\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import shutil, os\n",
      "from os import path\n",
      "import sqlite3\n",
      "import json\n",
      "from sklearn.externals import joblib"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## SCRIPT:\n",
      "- setup project folder layout\n",
      "- Load iris data, persist it, add necessary *meta-data*\n",
      "- Create feuture extrators: PCA, 2nd Polynomials, Subset Sampling (row-wise), Persist them, add *meta-data*, Persist intermediate data \n",
      "- Configure pipeline (deep architecture), test if the pipeline matches \n",
      "- Run the pipeline on data - stepwise / as-a-whole?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## LOWER IO HELPER FUNCTIONS\n",
      "def insert_to_db(db, table, row):\n",
      "    \"\"\"\n",
      "    db: sqlite3 datafile path\n",
      "    tablename: table in the database\n",
      "    row: dict of {col:value}\n",
      "    \"\"\"\n",
      "    conn = sqlite3.connect(db)\n",
      "    c = conn.cursor()\n",
      "    statement = \"\"\"INSERT INTO %s (%s) VALUES (%s)\"\"\" % (table, \n",
      "                                                         ','.join(row.keys()), \n",
      "                                                         ','.join([\"'%s'\" % (s,) for s in row.values()]))\n",
      "\n",
      "    print statement\n",
      "    c.execute(statement)\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    \n",
      "def query_db(db, table, columns = '*', where = None):\n",
      "    \"\"\"\n",
      "    return a list of dict (with columns as KEYS, and query results as VALUES)\n",
      "    \"\"\"\n",
      "    conn = sqlite3.connect(db)\n",
      "    c = conn.cursor()\n",
      "    where = ' where ' + where if where else ''\n",
      "    statement = \"SELECT %s from %s%s\" % (','.join(columns), table, where)\n",
      "    rows = c.execute(statement)\n",
      "    column_names = columns if columns != '*' else [x[0] for x in c.description]\n",
      "    results = [dict(zip(column_names, row)) for row in rows]\n",
      "    conn.commit()\n",
      "    conn.close()\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## TEST LOW IO\n",
      "print query_db('data/prototype_pipe/data/meta.db', 'data_meta')\n",
      "print query_db('data/prototype_pipe/data/meta.db', 'data_meta', columns=[\"name\"])\n",
      "print query_db('data/prototype_pipe/data/meta.db', 'data_meta', columns=['name', 'features'], \n",
      "               where = 'name = \"iris_original\"')\n",
      "print query_db('data/prototype_pipe/data/meta.db', 'data_meta', where = \"name='NOEXIST'\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'name': u'iris_original', 'features': u'[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]'}]\n",
        "[{'name': u'iris_original'}]\n",
        "[{'name': u'iris_original', 'features': u'[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]'}]\n",
        "[]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Data Analysis LEVEL HELPER FUNCTIONS\n",
      "\n",
      "def get_config(project_path, item):\n",
      "    CONFIG = {  'data_folder': path.abspath(path.join(project_path, 'data'))\n",
      "              , 'model_folder': path.abspath(path.join(project_path, 'models'))\n",
      "              , 'temp_folder': path.abspath(path.join(project_path, 'temp'))\n",
      "              , 'data_meta_db': path.abspath(path.join(project_path, 'data/meta.db'))\n",
      "              , 'data_meta_table': 'data_meta'}\n",
      "    return CONFIG[item]\n",
      "\n",
      "def write_project(container_path, project_name):\n",
      "    ## check if project exists - overwrite\n",
      "    project_path = path.abspath(path.join(container_path, project_name))\n",
      "    if path.exists(project_path):\n",
      "        shutil.rmtree(project_path)\n",
      "    ## create folder for project\n",
      "    os.mkdir(project_path)\n",
      "    data_folder = get_config(project_path, 'data_folder')\n",
      "    model_folder = get_config(project_path, 'model_folder')\n",
      "    temp_folder = get_config(project_path, 'temp_folder')\n",
      "    ## data folder\n",
      "    os.mkdir(data_folder)\n",
      "    ### meta db\n",
      "    data_meta_db = get_config(project_path, 'data_meta_db')\n",
      "    conn = sqlite3.connect(data_meta_db)\n",
      "    c = conn.cursor()\n",
      "    c.execute(\"\"\"CREATE TABLE data_meta\n",
      "                (name text, features text)\n",
      "            \"\"\")\n",
      "    conn.commit()\n",
      "    conn.close()   \n",
      "    ## models folder\n",
      "    os.mkdir(model_folder)\n",
      "    ## temp folder\n",
      "    os.mkdir(temp_folder)\n",
      "    return project_path\n",
      "    \n",
      "def write_data(project_path, data_meta, data_bulk):\n",
      "    \"\"\"\n",
      "    project_path: the path to the root of project\n",
      "    data_meta: {name:??, path:??, feature_names:??}\n",
      "    data_bulk: whatever things (objects that can be put in hdfs)\n",
      "    \"\"\"\n",
      "    ## find the way\n",
      "    data_folder = get_config(project_path, 'data_folder')\n",
      "    data_meta_db = get_config(project_path, 'data_meta_db')\n",
      "    data_meta_table = get_config(project_path, 'data_meta_table')\n",
      "    ## insert meta information to meta.db\n",
      "    insert_to_db(db = data_meta_db, table = data_meta_table, row = data_meta)\n",
      "    ## save data_bulk into database\n",
      "    bulk_folder = path.join(data_folder, data_meta['name'])\n",
      "    os.mkdir(bulk_folder)\n",
      "    bulk_file = path.join(bulk_folder, 'bulk.pkl')\n",
      "    joblib.dump(data_bulk, bulk_file)\n",
      "    \n",
      "def read_data_meta(project_path, data_name):\n",
      "    \"\"\"\n",
      "    return dictionary of data meta, as in the data/meta.db/data_meta table\n",
      "    \"\"\"\n",
      "    pass\n",
      "\n",
      "def read_data_bulk(project_path, data_name):\n",
      "    \"\"\"\n",
      "    return the bulk of data as what it is saved as\n",
      "    \"\"\"\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## clean up all the existing folder\n",
      "project_name = 'prototype_pipe'\n",
      "container_path = 'data'\n",
      "\n",
      "project_path = write_project(container_path, project_name)\n",
      "\n",
      "!tree data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[01;34mdata\u001b[00m\r\n",
        "\u2514\u2500\u2500 \u001b[01;34mprototype_pipe\u001b[00m\r\n",
        "    \u251c\u2500\u2500 \u001b[01;34mdata\u001b[00m\r\n",
        "    \u2502\u00a0\u00a0 \u2514\u2500\u2500 meta.db\r\n",
        "    \u251c\u2500\u2500 \u001b[01;34mmodels\u001b[00m\r\n",
        "    \u2514\u2500\u2500 \u001b[01;34mtemp\u001b[00m\r\n",
        "\r\n",
        "4 directories, 1 file\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Data Management - create, presiste meta-data\n",
      "iris = datasets.load_iris()\n",
      "iris_meta = {'name': 'iris_original', \n",
      "             'features': json.dumps([\"SepalLength\", \"SepalWidth\", \n",
      "                                     'PetalLength', 'PetalWidth'])}\n",
      "iris_bulk = (iris.data, iris.target)\n",
      "write_data(project_path, iris_meta, iris_bulk)\n",
      "\n",
      "!tree data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "INSERT INTO data_meta (name,features) VALUES ('iris_original','[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]')\n",
        "\u001b[01;34mdata\u001b[00m\r\n",
        "\u2514\u2500\u2500 \u001b[01;34mprototype_pipe\u001b[00m\r\n",
        "    \u251c\u2500\u2500 \u001b[01;34mdata\u001b[00m\r\n",
        "    \u2502\u00a0\u00a0 \u251c\u2500\u2500 \u001b[01;34miris_original\u001b[00m\r\n",
        "    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bulk.pkl\r\n",
        "    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 bulk.pkl_01.npy\r\n",
        "    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 bulk.pkl_02.npy\r\n",
        "    \u2502\u00a0\u00a0 \u2514\u2500\u2500 meta.db\r\n",
        "    \u251c\u2500\u2500 \u001b[01;34mmodels\u001b[00m\r\n",
        "    \u2514\u2500\u2500 \u001b[01;34mtemp\u001b[00m\r\n",
        "\r\n",
        "5 directories, 4 files\r\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Model management - create, persiste, meta-data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Construct pipeline - configure, match steps, persist"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Rung pipeline to see the result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}